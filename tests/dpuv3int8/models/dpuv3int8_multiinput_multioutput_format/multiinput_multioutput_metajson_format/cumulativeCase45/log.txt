[INFO] parse raw model     :  0%|          | 0/271 [00:00<?, ?it/s]                          [INFO] parse raw model     :100%|██████████| 271/271 [00:00<00:00, 32600.71it/s]             
[INFO] infer shape (NHWC)  :  0%|          | 0/220 [00:00<?, ?it/s]                          [INFO] infer shape (NHWC)  :100%|██████████| 220/220 [00:00<00:00, 4849.37it/s]              
[INFO] generate xmodel     :  0%|          | 0/220 [00:00<?, ?it/s]                          [INFO] generate xmodel     : 26%|██▌       | 57/220 [00:00<00:00, 545.16it/s]                [INFO] generate xmodel     : 37%|███▋      | 82/220 [00:00<00:00, 387.80it/s]                [INFO] generate xmodel     : 47%|████▋     | 103/220 [00:00<00:00, 247.26it/s]               [INFO] generate xmodel     : 55%|█████▍    | 120/220 [00:00<00:00, 129.41it/s]               [INFO] generate xmodel     : 61%|██████    | 134/220 [00:00<00:00, 98.15it/s]                [INFO] generate xmodel     : 66%|██████▋   | 146/220 [00:01<00:00, 85.90it/s]                [INFO] generate xmodel     : 71%|███████▏  | 157/220 [00:01<00:00, 76.42it/s]                [INFO] generate xmodel     : 75%|███████▌  | 166/220 [00:01<00:00, 71.70it/s]                [INFO] generate xmodel     : 80%|███████▉  | 175/220 [00:01<00:01, 38.93it/s]                [INFO] generate xmodel     : 83%|████████▎ | 182/220 [00:02<00:01, 23.85it/s]                [INFO] generate xmodel     : 85%|████████▌ | 187/220 [00:02<00:01, 25.28it/s]                [INFO] generate xmodel     : 87%|████████▋ | 192/220 [00:02<00:01, 19.74it/s]                [INFO] generate xmodel     : 89%|████████▉ | 196/220 [00:03<00:01, 20.54it/s]                [INFO] generate xmodel     : 91%|█████████ | 200/220 [00:03<00:00, 21.38it/s]                [INFO] generate xmodel     : 92%|█████████▏| 203/220 [00:03<00:01, 13.90it/s]                [INFO] generate xmodel     : 94%|█████████▎| 206/220 [00:03<00:00, 14.83it/s]                [INFO] generate xmodel     : 96%|█████████▋| 212/220 [00:04<00:00, 15.63it/s]                [INFO] generate xmodel     :100%|██████████| 220/220 [00:04<00:00, 52.24it/s]                ['/proj/xsjhdstaff3/paolod/perforce/RDI_paolod_Dev_work/src/DeepLearning/xilinx/gitlab/vai-toolchain/SC/HwAbstraction', '/wrk/hdstaff/paolod/perforce/RDI_paolod_Dev_work/src/DeepLearning/xilinx/gitlab/vai-toolchain', '/wrk/hdstaff/paolod/perforce/RDI_paolod_Dev_work/temp/anaconda2/envs/XIR2/lib/python37.zip', '/wrk/hdstaff/paolod/perforce/RDI_paolod_Dev_work/temp/anaconda2/envs/XIR2/lib/python3.7', '/wrk/hdstaff/paolod/perforce/RDI_paolod_Dev_work/temp/anaconda2/envs/XIR2/lib/python3.7/lib-dynload', '/wrk/hdstaff/paolod/perforce/RDI_paolod_Dev_work/temp/anaconda2/envs/XIR2/lib/python3.7/site-packages']
[INFO] ignore pretty_errors package
no wait
proto examples/tf_resnetv1_50_imagenet_224_224_6.97G/quantized/quantize_eval_model.pb
caffe None
[INFO] tensorflow model: examples/tf_resnetv1_50_imagenet_224_224_6.97G/quantized/quantize_eval_model.pb
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198030>> [4, 28, 28, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198070>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1980b0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1980f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198130>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198170>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1981b0>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1981f0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198230>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198270>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1982b0>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1982f0>> [128, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198330>> [128, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198370>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1983b0>> [4, 28, 28, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1983f0>> [4, 112, 112, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198430>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198470>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1984f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198530>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1985b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1985f0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198630>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1986b0>> [64, 7, 7, 3]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1986f0>> [64, 7, 7, 3]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198730>> [256, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1987b0>> [128, 3, 3, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198830>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1988b0>> [4, 28, 28, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1988f0>> [4, 58, 58, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198930>> [128, 3, 3, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1989b0>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1989f0>> [64, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198a30>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198a70>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198ab0>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198af0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198b30>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198b70>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198bb0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198bf0>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198c30>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198c70>> [512, 1, 1, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198cb0>> [512, 1, 1, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198cf0>> [4, 28, 28, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198d30>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198d70>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198db0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198df0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198e30>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198e70>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198eb0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198ef0>> [4, 112, 112, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198f30>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198f70>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd198fb0>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199030>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199070>> [4, 112, 112, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1990b0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1990f0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199130>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199170>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1991b0>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1991f0>> [64, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199230>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199270>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1992b0>> [128, 3, 3, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1992f0>> [128, 3, 3, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199330>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199370>> [256, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1993b0>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1993f0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199430>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199470>> [256, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1994b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1994f0>> [512, 1, 1, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199530>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529570>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199570>> [4, 14, 14, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1995b0>> [4, 14, 14, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1995f0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199630>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199670>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1996b0>> [4, 224, 224, 3]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c25296f0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1996f0>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529730>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199730>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529770>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199770>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c25297b0>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1997b0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1997f0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199830>> [1]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529870>> [256, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199870>> [4, 224, 224, 3]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1998b0>> [128, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c25298f0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1998f0>> [128, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529930>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199930>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529970>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199970>> [4, 14, 14, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c25299b0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1999b0>> [4, 14, 14, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1999f0>> [512, 1, 1, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529a30>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199a30>> [64, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529a70>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199a70>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529ab0>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199ab0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199af0>> [64, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529b30>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199b30>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529b70>> [4, 28, 28, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199b70>> [4, 14, 14, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199bb0>> [4, 28, 28, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529bf0>> [4, 28, 28, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199bf0>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529c30>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199c30>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529c70>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199c70>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529cb0>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199cb0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529cf0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199cf0>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529d30>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199d30>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199d70>> [4, 58, 58, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529db0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199db0>> [64, 3, 3, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529df0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199df0>> [64, 3, 3, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529e30>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199e30>> [512, 1, 1, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529e70>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199e70>> [512, 1, 1, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529eb0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199eb0>> [4, 230, 230, 3]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529ef0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199ef0>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529f30>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199f30>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199f70>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529f70>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd199fb0>> [64, 3, 3, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2529fb0>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192030>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192070>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1920b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1920f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192130>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192170>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1921b0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1921f0>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192230>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192270>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1922b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1922f0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192330>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192370>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1923b0>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1923f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192430>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192470>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1924b0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192530>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192570>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1925b0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1925f0>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192630>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192670>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1926b0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1926f0>> [128, 3, 3, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192730>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192770>> [128, 3, 3, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1927b0>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1927f0>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192830>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192870>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1928b0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1928f0>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192930>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192970>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1929b0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1929f0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192a30>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192a70>> [512, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192ab0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192af0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192b30>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192b70>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192bb0>> [4, 14, 14, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192bf0>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192c30>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192c70>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192cf0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192d30>> [512, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192d70>> [4, 7, 7, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192db0>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192e30>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192eb0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192ef0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd192f30>> [4, 14, 14, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193330>> [64, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193470>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193570>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1936b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193730>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193770>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1937b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1937f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193830>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193870>> [512, 3, 3, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1938b0>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1938f0>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193930>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193970>> [512, 1, 1, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1939b0>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1939f0>> [512, 1, 1, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193a30>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193a70>> [256, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193ab0>> [256, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193af0>> [2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193b30>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193b70>> [512, 3, 3, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193bb0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193bf0>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193c30>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193c70>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193cb0>> [1024, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193cf0>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193d30>> [1024, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193d70>> [4, 7, 7, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193db0>> [2048, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193df0>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193e30>> [4, 16, 16, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193e70>> [4, 16, 16, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193eb0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193ef0>> [4, 7, 7, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193f30>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193f70>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd193fb0>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194030>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194070>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1940b0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1940f0>> [4, 7, 7, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194130>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194170>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1941b0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1941f0>> [4, 230, 230, 3]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194230>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194270>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1942b0>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1942f0>> [4, 7, 7, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194330>> [4, 7, 7, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194370>> [4, 7, 7, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1943b0>> [1024, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1943f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194430>> [2048, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194470>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1944b0>> [2048, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1944f0>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194530>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194570>> [256, 3, 3, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1945b0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1945f0>> [4, 7, 7, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194630>> [4, 7, 7, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194670>> [4, 7, 7, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1946b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1946f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194730>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194770>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1947b0>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1947f0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194830>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194870>> [1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1948b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1948f0>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194930>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194970>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1949b0>> [4, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1949f0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194a30>> [256, 1, 1, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194a70>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194ab0>> [4, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194af0>> [4, 14, 14, 1024]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194b30>> [4, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194b70>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c2cd4bb0>> [2]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194bb0>> [4, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194bf0>> [4, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194c30>> [4, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194c70>> [1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194cb0>> [4, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194cf0>> [4, 1, 1, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194d30>> [4, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194d70>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194db0>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194df0>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194e30>> [4, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194e70>> [4, 1, 1, 1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194eb0>> [4, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194ef0>> [1000, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194f30>> [1000]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194f70>> [1000, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd194fb0>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195030>> [2048, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195070>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1950b0>> [2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1950f0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195130>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195170>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1951b0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1951f0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195230>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195270>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1952b0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1952f0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195330>> [2048, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195370>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1953b0>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1953f0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195430>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195470>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1954b0>> [512, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1954f0>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195530>> [2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195570>> [512, 3, 3, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1955b0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1955f0>> [2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195630>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195670>> [2048, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1956b0>> [512, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1956f0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195730>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195770>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1957b0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1957f0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195830>> [2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195870>> [512, 3, 3, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1958b0>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1958f0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195930>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195970>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1959b0>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1959f0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195a30>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195a70>> [2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195ab0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195af0>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195b30>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195b70>> [2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195bb0>> [2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195bf0>> [512, 3, 3, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195c30>> [512, 3, 3, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195c70>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195cb0>> [512, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195cf0>> [512, 1, 1, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4c1bbdd30>> [4, 14, 14, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195d30>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195d70>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195db0>> [4, 7, 7, 2048]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195df0>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195e30>> [2048, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195e70>> [2048, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195eb0>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195ef0>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195f30>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195f70>> [4, 7, 7, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd195fb0>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196030>> [4, 28, 28, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196070>> [64, 3, 3, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1960b0>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1960f0>> [64, 3, 3, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196130>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196170>> [2]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1961b0>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1961f0>> [512, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196230>> [128, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196270>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1962b0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1962f0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196330>> [128, 3, 3, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196370>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1963b0>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1963f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196430>> [256, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196470>> [4, 30, 30, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1964b0>> [128, 1, 1, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1964f0>> [256, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196530>> [512, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196570>> [64, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1965b0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1965f0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196630>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196670>> [4, 14, 14, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1966b0>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1966f0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196730>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196770>> [4, 30, 30, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1967b0>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1967f0>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196830>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196870>> [4, 56, 56, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1968b0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1968f0>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196930>> [256, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196970>> [256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1969b0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd1969f0>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196a30>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196a70>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196ab0>> [128, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196af0>> [4, 14, 14, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196b30>> [4, 28, 28, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196b70>> [512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196bb0>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196bf0>> [4, 28, 28, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196c30>> [4, 28, 28, 512]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196c70>> [256, 1, 1, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196cb0>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196cf0>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196d30>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196d70>> [128, 1, 1, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196db0>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196df0>> [128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196e30>> [4, 56, 56, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196e70>> [4, 28, 28, 256]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196eb0>> [64, 3, 3, 64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196ef0>> [128, 3, 3, 128]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196f30>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196f70>> [64]
<bound method PyCapsule.get_name of <xir.Op object at 0x7fa4bd196fb0>> [4, 14, 14, 128]
 ############################################# 
 ######  Hyper Graph Construction 
 ############################################# 
 ############################################# 
 ######  Hyper Graph Construction
 ############################################# 
resnet_v1_50/block1/unit_3/bottleneck_v1/Pad pad [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool maxpool2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_2/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3)] 2 1
2
resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_2/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block3/unit_5/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block3/unit_5/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3)] 2 1
2
resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=6)] 1 1
1
resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block1/unit_2/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_3/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block3/unit_3/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3)] 2 1
2
resnet_v1_50/predictions/Reshape_1 reshape [DeephiQuantizationElements(bits=8, fraction=7)] 1 1
1
resnet_v1_50/predictions/Softmax softmax [DeephiQuantizationElements(bits=8, fraction=2)] 1 1
1
resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=11), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/predictions/Reshape reshape [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=2)] 1 1
1
resnet_v1_50/SpatialSqueeze squeeze [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=2)] 1 1
1
resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block4/unit_3/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=2)] 1 1
1
resnet_v1_50/block4/unit_3/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=2)] 2 1
2
resnet_v1_50/logits/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=12)] 1 1
1
resnet_v1_50/block4/unit_1/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=2)] 2 1
2
resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/pool5 avgpool2d [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block4/unit_2/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=2)] 1 1
1
resnet_v1_50/block4/unit_2/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=2)] 2 1
2
resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=11), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block4/unit_1/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=2), DeephiQuantizationElements(bits=8, fraction=2)] 1 1
1
resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_1/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/Pad pad [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_1/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 2 1
2
resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool maxpool2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block1/unit_3/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=6)] 1 1
1
resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_1/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3)] 2 1
2
resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_1/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block2/unit_1/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=-1), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=12), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_6/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3)] 2 1
2
resnet_v1_50/block3/unit_6/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/Pad pad [DeephiQuantizationElements(bits=8, fraction=-1), DeephiQuantizationElements(bits=8, fraction=-1)] 1 1
1
resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=6)] 1 1
1
resnet_v1_50/block3/unit_6/bottleneck_v1/shortcut/MaxPool maxpool2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_6/bottleneck_v1/Pad pad [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block3/unit_4/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3)] 2 1
2
resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block3/unit_4/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_1/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 2 1
2
resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_2/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_2/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 2 1
2
resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=8), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block1/unit_3/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 2 1
2
resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_3/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/block2/unit_3/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4)] 2 1
2
resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
input data [DeephiQuantizationElements(bits=8, fraction=-1)] 0 1
0
resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=6), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/Relu relu [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block2/unit_4/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=3)] 2 1
2
resnet_v1_50/block1/unit_2/bottleneck_v1/add add [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 2 1
2
resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=9), DeephiQuantizationElements(bits=8, fraction=5)] 1 1
1
resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D conv2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=7), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
resnet_v1_50/pool1/MaxPool maxpool2d [DeephiQuantizationElements(bits=8, fraction=3), DeephiQuantizationElements(bits=8, fraction=3)] 1 1
1
resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Relu relu [DeephiQuantizationElements(bits=8, fraction=4), DeephiQuantizationElements(bits=8, fraction=4)] 1 1
1
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Relu [4, 7, 7, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D_bias [2048] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D_bias_fixneuron [64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D_bias [64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 56, 56, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D_bias [128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D_weights_fixneuron [64, 3, 3, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D_weights [64, 3, 3, 64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D [4, 28, 28, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/predictions/Shape_const_const [2] dict_keys(['data', 'data_type', 'quant_in_signed', 'quant_out_signed', 'shape'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D [4, 56, 56, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Relu [4, 28, 28, 128] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D [4, 28, 28, 128] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D_bias_fixneuron [128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D_bias [128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D_weights_fixneuron [256, 1, 1, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D_weights_fixneuron [128, 1, 1, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D_weights [128, 1, 1, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/Relu/aquant [4, 28, 28, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D_weights_fixneuron [256, 1, 1, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D_weights_fixneuron [512, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D_weights [64, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Relu/aquant [4, 28, 28, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/Relu/aquant [4, 56, 56, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/Relu [4, 56, 56, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D_weights [128, 3, 3, 128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/Pad/aquant [4, 30, 30, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/Pad [4, 30, 30, 128] dict_keys(['constant_values', 'mode', 'paddings', 'quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/add [4, 56, 56, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 56, 56, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D_weights [512, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D [4, 56, 56, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D [4, 28, 28, 128] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Relu/aquant [4, 28, 28, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool/aquant [4, 14, 14, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Relu [4, 28, 28, 128] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D_bias_fixneuron [128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D_bias [128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D_weights_fixneuron [128, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 28, 28, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D [4, 28, 28, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/FusedBatchNorm/add/aquant [4, 28, 28, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Relu [4, 28, 28, 128] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D_weights_fixneuron [256, 1, 1, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D_weights [256, 1, 1, 64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool [4, 14, 14, 512] dict_keys(['global', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D [4, 28, 28, 128] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D_bias_fixneuron [128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D_bias [128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Relu/aquant [4, 56, 56, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Relu [4, 56, 56, 64] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D_weights [128, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/Relu/aquant [4, 28, 28, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/Relu [4, 28, 28, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D [4, 56, 56, 64] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D_bias_fixneuron [64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D_bias [64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D [4, 14, 14, 128] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D_bias_fixneuron [128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D_bias [128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D_weights_fixneuron [128, 3, 3, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D_weights [64, 3, 3, 64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D [4, 28, 28, 128] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D_bias_fixneuron [128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Relu/aquant [4, 56, 56, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/add [4, 56, 56, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/Pad/aquant [4, 230, 230, 3] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D [4, 28, 28, 128] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D_weights_fixneuron [512, 1, 1, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D_weights [512, 1, 1, 128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D_bias_fixneuron [128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D_weights_fixneuron [64, 3, 3, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D_weights [256, 1, 1, 64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D_weights [64, 3, 3, 64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D_bias [128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/Pad/aquant [4, 58, 58, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Relu/aquant [4, 56, 56, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Relu [4, 56, 56, 64] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/Relu [4, 28, 28, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/add [4, 28, 28, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D [4, 56, 56, 64] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D_weights_fixneuron [128, 3, 3, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D_bias_fixneuron [64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D_weights [128, 3, 3, 128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/add [4, 28, 28, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D [4, 56, 56, 64] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 14, 14, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D_bias_fixneuron [64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D_bias [64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D_weights_fixneuron [64, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Relu/aquant [4, 28, 28, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D_weights [64, 1, 1, 64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Relu [4, 28, 28, 128] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D_weights [64, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/pool1/MaxPool/aquant [4, 56, 56, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D_weights [512, 1, 1, 128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 28, 28, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Relu/aquant [4, 14, 14, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/pool1/MaxPool [4, 56, 56, 64] dict_keys(['global', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Relu [4, 14, 14, 128] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Relu/aquant [4, 28, 28, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D_bias [128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D_weights_fixneuron [128, 1, 1, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Relu [4, 28, 28, 128] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D_weights [128, 1, 1, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/conv1/Relu/aquant [4, 112, 112, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT input/aquant [4, 224, 224, 3] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D [4, 56, 56, 64] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/pool5/scale_value_const [1] dict_keys(['data', 'data_type', 'quant_in_signed', 'quant_out_signed', 'shape'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/Relu [4, 28, 28, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D_bias_fixneuron [64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/add [4, 28, 28, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D [4, 28, 28, 128] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D [4, 28, 28, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/FusedBatchNorm/add/aquant [4, 56, 56, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D_bias_fixneuron [128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Relu [4, 56, 56, 64] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/conv1/Relu [4, 112, 112, 64] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT input [4, 224, 224, 3] dict_keys(['data_type', 'quant_in_signed', 'quant_out_signed', 'shape'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D [4, 28, 28, 128] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D_bias_fixneuron [128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D_bias [128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/add [4, 28, 28, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D [4, 56, 56, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/predictions/Reshape_1/aquant [4, 1000] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D [4, 28, 28, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 28, 28, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/Relu [4, 14, 14, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D_weights_fixneuron [512, 1, 1, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/add [4, 14, 14, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D_weights [512, 1, 1, 128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D_bias_fixneuron [1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D_weights_fixneuron [512, 1, 1, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D_weights_fixneuron [256, 1, 1, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D [4, 14, 14, 1024] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/Relu/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/Relu [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/add [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D_bias [1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D_weights_fixneuron [1024, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D_weights [1024, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D_weights_fixneuron [256, 3, 3, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D_weights [256, 3, 3, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D [4, 28, 28, 64] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D_weights_fixneuron [128, 1, 1, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D_weights [128, 1, 1, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D_bias [1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D_weights_fixneuron [1024, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D_weights [1024, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_weights_fixneuron [256, 3, 3, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_weights [256, 3, 3, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/conv1/Conv2D_weights_fixneuron [64, 7, 7, 3] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/conv1/Conv2D_weights [64, 7, 7, 3] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D_weights [256, 1, 1, 64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/conv1/Conv2D [4, 112, 112, 64] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D_weights_fixneuron [128, 3, 3, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D_weights [128, 3, 3, 128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Relu/aquant [4, 28, 28, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Relu [4, 28, 28, 64] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/Relu/aquant [4, 28, 28, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/Relu [4, 28, 28, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/Pad [4, 58, 58, 64] dict_keys(['constant_values', 'mode', 'paddings', 'quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D_bias [64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D_weights_fixneuron [64, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Relu/aquant [4, 56, 56, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D_weights [256, 1, 1, 64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D [4, 28, 28, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Relu/aquant [4, 56, 56, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Relu [4, 56, 56, 64] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool/aquant [4, 28, 28, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Relu [4, 56, 56, 64] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D [4, 56, 56, 64] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool [4, 28, 28, 256] dict_keys(['global', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D_bias_fixneuron [64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D_bias [64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/FusedBatchNorm/add/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D [4, 14, 14, 1024] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D_bias [64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/add [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D [4, 14, 14, 1024] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D_weights_fixneuron [64, 3, 3, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D_bias_fixneuron [1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/Relu/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D_bias_fixneuron [1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/Relu/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D_weights [256, 1, 1, 1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/Relu [4, 7, 7, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/add [4, 7, 7, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D_weights_fixneuron [256, 1, 1, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/Pad [4, 230, 230, 3] dict_keys(['constant_values', 'mode', 'paddings', 'quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Relu/aquant [4, 28, 28, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D [4, 7, 7, 1024] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D_weights [2048, 1, 1, 1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D_bias_fixneuron [1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D [4, 7, 7, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D_bias [1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 7, 7, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D [4, 14, 14, 1024] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D_bias [1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D [4, 7, 7, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Relu [4, 7, 7, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D_weights [1024, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D_weights_fixneuron [2048, 1, 1, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D_weights_fixneuron [1024, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Relu/aquant [4, 7, 7, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D_weights_fixneuron [256, 3, 3, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Relu [4, 28, 28, 128] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/conv1/Conv2D_bias_fixneuron [64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/conv1/Conv2D_bias [64] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/Relu/aquant [4, 56, 56, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block1/unit_2/bottleneck_v1/Relu [4, 56, 56, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D_weights_fixneuron [256, 1, 1, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D_weights [256, 1, 1, 1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D [4, 14, 14, 1024] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D_bias_fixneuron [1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/Relu/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/Relu [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/add [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/predictions/Reshape_1 [4, 1000] dict_keys(['quant_in_signed', 'quant_out_signed', 'shape'])
XIR ATT resnet_v1_50/predictions/Softmax [4, 1000] dict_keys(['axis', 'quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/predictions/Reshape/aquant [4, 1000] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/predictions/Reshape [4, 1000] dict_keys(['quant_in_signed', 'quant_out_signed', 'shape'])
XIR ATT resnet_v1_50/SpatialSqueeze/aquant [4, 1000] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/SpatialSqueeze [4, 1000] dict_keys(['axis', 'quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/Relu/aquant [4, 7, 7, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/Relu [4, 7, 7, 2048] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/add [4, 7, 7, 2048] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 7, 7, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/logits/BiasAdd/aquant [4, 1, 1, 1000] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/logits/Conv2D [4, 1, 1, 1000] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/logits/Conv2D_bias_fixneuron [1000] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/logits/Conv2D_bias [1000] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/logits/Conv2D_weights_fixneuron [1000, 1, 1, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/logits/Conv2D_weights [1000, 1, 1, 2048] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/pool5 [4, 1, 1, 2048] dict_keys(['count_include_invalid', 'count_include_pad', 'global', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D_weights_fixneuron [2048, 1, 1, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D_bias_fixneuron [2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D [4, 7, 7, 2048] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/pool5/mul [4, 1, 1, 2048] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D [4, 7, 7, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/pool5/mul/aquant [4, 1, 1, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Relu/aquant [4, 7, 7, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Relu [4, 7, 7, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/Relu/aquant [4, 7, 7, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/Relu [4, 7, 7, 2048] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/add [4, 7, 7, 2048] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 7, 7, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Relu/aquant [4, 7, 7, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Relu [4, 7, 7, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D [4, 7, 7, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D_weights_fixneuron [512, 1, 1, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D_weights [512, 1, 1, 2048] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D [4, 7, 7, 2048] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D_bias_fixneuron [2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D_bias [2048] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D_weights_fixneuron [2048, 1, 1, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D_weights [2048, 1, 1, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D_weights_fixneuron [64, 1, 1, 64] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D [4, 7, 7, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Relu/aquant [4, 7, 7, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Relu [4, 7, 7, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/Relu [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D_weights_fixneuron [512, 3, 3, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D_weights_fixneuron [256, 1, 1, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D_weights [512, 3, 3, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D_weights [256, 1, 1, 1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D [4, 7, 7, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D_bias [1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D_weights_fixneuron [1024, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Relu/aquant [4, 7, 7, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D_weights [1024, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Relu [4, 7, 7, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/add [4, 7, 7, 2048] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D_weights_fixneuron [256, 1, 1, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 7, 7, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D_weights [256, 1, 1, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D [4, 7, 7, 2048] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D_bias [2048] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D_bias_fixneuron [2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D_weights_fixneuron [512, 3, 3, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D_bias [2048] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D_weights [512, 3, 3, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/FusedBatchNorm/add/aquant [4, 7, 7, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D_weights_fixneuron [512, 1, 1, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Relu [4, 7, 7, 512] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D_weights [512, 1, 1, 128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D [4, 7, 7, 2048] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Relu/aquant [4, 28, 28, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D_bias_fixneuron [2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D_bias_fixneuron [1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D_bias [1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D_weights_fixneuron [512, 3, 3, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D_weights_fixneuron [1024, 1, 1, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/Relu [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D_weights [512, 3, 3, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D_weights [1024, 1, 1, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Relu/aquant [4, 7, 7, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D_weights_fixneuron [512, 1, 1, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D_weights [2048, 1, 1, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D_weights [512, 1, 1, 2048] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D_weights [256, 3, 3, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/add [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/Relu/aquant [4, 7, 7, 2048] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/Pad/aquant [4, 16, 16, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/Relu [4, 7, 7, 2048] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/Pad [4, 16, 16, 256] dict_keys(['constant_values', 'mode', 'paddings', 'quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D_weights_fixneuron [2048, 1, 1, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D_weights [2048, 1, 1, 512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/shortcut/MaxPool/aquant [4, 7, 7, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D [4, 7, 7, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/shortcut/MaxPool [4, 7, 7, 1024] dict_keys(['global', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Relu/aquant [4, 7, 7, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D_weights_fixneuron [1024, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D_weights [1024, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D_weights_fixneuron [256, 3, 3, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D_weights [256, 3, 3, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D_weights_fixneuron [256, 1, 1, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D_weights [256, 1, 1, 1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/predictions/Reshape/shape_const [2] dict_keys(['data', 'data_type', 'quant_in_signed', 'quant_out_signed', 'shape'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D_weights_fixneuron [256, 3, 3, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D_weights [256, 3, 3, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Relu/aquant [4, 28, 28, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Relu [4, 28, 28, 128] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D_weights_fixneuron [256, 1, 1, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D_weights [256, 1, 1, 1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D_bias [1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D_weights_fixneuron [1024, 1, 1, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D_weights_fixneuron [128, 3, 3, 128] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D_weights [128, 3, 3, 128] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D_bias_fixneuron [512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 28, 28, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D_weights [1024, 1, 1, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Relu/aquant [4, 14, 14, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Relu [4, 14, 14, 256] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D [4, 14, 14, 256] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D_bias_fixneuron [256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D_bias [256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D_weights_fixneuron [256, 3, 3, 256] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D_weights [256, 3, 3, 256] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/add [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm/add/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D [4, 14, 14, 1024] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D_bias_fixneuron [1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/Relu/aquant [4, 14, 14, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block3/unit_1/bottleneck_v1/Relu [4, 14, 14, 1024] dict_keys(['quant_in_signed', 'quant_out_signed'])
XIR ATT resnet_v1_50/block2/unit_3/bottleneck_v1/Relu/aquant [4, 28, 28, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D_bias [512] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D_weights_fixneuron [512, 1, 1, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'round_mode'])
XIR ATT resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D_weights [512, 1, 1, 1024] dict_keys(['data', 'data_type', 'shape'])
XIR ATT resnet_v1_50/block3/unit_6/bottleneck_v1/Relu/aquant [4, 7, 7, 1024] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/Relu/aquant [4, 14, 14, 512] dict_keys(['bit_width', 'fix_point', 'if_signed', 'quant_in_bit_width', 'quant_in_quantize_pos', 'quant_in_round_mode', 'quant_in_signed', 'quant_out_bit_width', 'quant_out_quantize_pos', 'quant_out_round_mode', 'quant_out_signed', 'round_mode'])
XIR ATT resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D [4, 14, 14, 512] dict_keys(['dilation', 'kernel', 'pad', 'pad_mode', 'quant_in_signed', 'quant_out_signed', 'stride'])
Floyd & Warshall
BFS
 ############################################# 
 ######  Parameters Assimilation
 ############################################# 
164
 ############################################# 
 ######  Assimilating Fix Neurons
 ############################################# 
83
 ############################################# 
 ######  Assimilating Relu
 ############################################# 
49
 ############################################# 
 ######  Assimilating LeakyRelu
 ############################################# 
0
 ############################################# 
 ######  Assimilating Padding
 ############################################# 
4
  0 const      resnet_v1_50/predictions/Reshape/shape_const Ops 0.000000 Shape TensorShapes(batch=1, width=1, height=1, channel=2)  IN [] OUT ['resnet_v1_50/predictions/Reshape']
  1 const      resnet_v1_50/predictions/Shape_const_const Ops 0.000000 Shape TensorShapes(batch=1, width=1, height=1, channel=2)  IN [] OUT ['resnet_v1_50/predictions/Reshape_1']
  2 data       input Ops 0.000000 Shape TensorShapes(batch=4, width=224, height=224, channel=3)  IN [] OUT ['resnet_v1_50/conv1/Conv2D']
  3 conv2d     resnet_v1_50/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=112, height=112, channel=64)  IN ['input'] OUT ['resnet_v1_50/pool1/MaxPool']
  4 maxpool2d  resnet_v1_50/pool1/MaxPool Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/conv1/Conv2D'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D']
  5 conv2d     resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/pool1/MaxPool'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/add']
  6 conv2d     resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/pool1/MaxPool'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D']
  7 conv2d     resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D']
  8 conv2d     resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/add']
  9 add        resnet_v1_50/block1/unit_1/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D', 'resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block1/unit_2/bottleneck_v1/add']
 10 conv2d     resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/block1/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D']
 11 conv2d     resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D']
 12 conv2d     resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block1/unit_2/bottleneck_v1/add']
 13 add        resnet_v1_50/block1/unit_2/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block1/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool']
 14 maxpool2d  resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=256)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/add']
 15 conv2d     resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D']
 16 conv2d     resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=64)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D']
 17 conv2d     resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=256)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/add']
 18 add        resnet_v1_50/block1/unit_3/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=256)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool', 'resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D']
 19 conv2d     resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/add']
 20 conv2d     resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D']
 21 conv2d     resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D']
 22 conv2d     resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/add']
 23 add        resnet_v1_50/block2/unit_1/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D', 'resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block2/unit_2/bottleneck_v1/add']
 24 conv2d     resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D']
 25 conv2d     resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D']
 26 conv2d     resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block2/unit_2/bottleneck_v1/add']
 27 add        resnet_v1_50/block2/unit_2/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block2/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block2/unit_3/bottleneck_v1/add']
 28 conv2d     resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D']
 29 conv2d     resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D']
 30 conv2d     resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block2/unit_3/bottleneck_v1/add']
 31 add        resnet_v1_50/block2/unit_3/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block2/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool']
 32 maxpool2d  resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=512)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/add']
 33 conv2d     resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D']
 34 conv2d     resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=128)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D']
 35 conv2d     resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=512)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/add']
 36 add        resnet_v1_50/block2/unit_4/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=512)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool', 'resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D']
 37 conv2d     resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/add']
 38 conv2d     resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D']
 39 conv2d     resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D']
 40 conv2d     resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/add']
 41 add        resnet_v1_50/block3/unit_1/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D', 'resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block3/unit_2/bottleneck_v1/add']
 42 conv2d     resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D']
 43 conv2d     resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D']
 44 conv2d     resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block3/unit_2/bottleneck_v1/add']
 45 add        resnet_v1_50/block3/unit_2/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block3/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block3/unit_3/bottleneck_v1/add']
 46 conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D']
 47 conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D']
 48 conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/add']
 49 add        resnet_v1_50/block3/unit_3/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block3/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block3/unit_4/bottleneck_v1/add']
 50 conv2d     resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D']
 51 conv2d     resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D']
 52 conv2d     resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block3/unit_4/bottleneck_v1/add']
 53 add        resnet_v1_50/block3/unit_4/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block3/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block3/unit_5/bottleneck_v1/add']
 54 conv2d     resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_4/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D']
 55 conv2d     resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D']
 56 conv2d     resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block3/unit_5/bottleneck_v1/add']
 57 add        resnet_v1_50/block3/unit_5/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block3/unit_4/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block3/unit_6/bottleneck_v1/shortcut/MaxPool']
 58 maxpool2d  resnet_v1_50/block3/unit_6/bottleneck_v1/shortcut/MaxPool Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=1024)  IN ['resnet_v1_50/block3/unit_5/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_6/bottleneck_v1/add']
 59 conv2d     resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_5/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D']
 60 conv2d     resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=256)  IN ['resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D']
 61 conv2d     resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=1024)  IN ['resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block3/unit_6/bottleneck_v1/add']
 62 add        resnet_v1_50/block3/unit_6/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=1024)  IN ['resnet_v1_50/block3/unit_6/bottleneck_v1/shortcut/MaxPool', 'resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D']
 63 conv2d     resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=2048)  IN ['resnet_v1_50/block3/unit_6/bottleneck_v1/add'] OUT ['resnet_v1_50/block4/unit_1/bottleneck_v1/add']
 64 conv2d     resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=512)  IN ['resnet_v1_50/block3/unit_6/bottleneck_v1/add'] OUT ['resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D']
 65 conv2d     resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=512)  IN ['resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D']
 66 conv2d     resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=2048)  IN ['resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block4/unit_1/bottleneck_v1/add']
 67 add        resnet_v1_50/block4/unit_1/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=2048)  IN ['resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D', 'resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block4/unit_2/bottleneck_v1/add']
 68 conv2d     resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=512)  IN ['resnet_v1_50/block4/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D']
 69 conv2d     resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=512)  IN ['resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D']
 70 conv2d     resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=2048)  IN ['resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block4/unit_2/bottleneck_v1/add']
 71 add        resnet_v1_50/block4/unit_2/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=2048)  IN ['resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block4/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block4/unit_3/bottleneck_v1/add']
 72 conv2d     resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=512)  IN ['resnet_v1_50/block4/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D']
 73 conv2d     resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=512)  IN ['resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D']
 74 conv2d     resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=2048)  IN ['resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block4/unit_3/bottleneck_v1/add']
 75 add        resnet_v1_50/block4/unit_3/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=7, height=7, channel=2048)  IN ['resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block4/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/pool5']
 76 avgpool2d  resnet_v1_50/pool5 Ops 0.000000 Shape TensorShapes(batch=4, width=1, height=1, channel=2048)  IN ['resnet_v1_50/block4/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/pool5/mul']
 77 mul        resnet_v1_50/pool5/mul Ops 0.000000 Shape TensorShapes(batch=4, width=1, height=1, channel=2048)  IN ['resnet_v1_50/pool5'] OUT ['resnet_v1_50/logits/Conv2D']
 78 conv2d     resnet_v1_50/logits/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=1, height=1, channel=1000)  IN ['resnet_v1_50/pool5/mul'] OUT ['resnet_v1_50/SpatialSqueeze']
 79 squeeze    resnet_v1_50/SpatialSqueeze Ops 0.000000 Shape TensorShapes(batch=1, width=4, height=1000, channel=1)  IN ['resnet_v1_50/logits/Conv2D'] OUT ['resnet_v1_50/predictions/Reshape']
 80 reshape    resnet_v1_50/predictions/Reshape Ops 0.000000 Shape TensorShapes(batch=1, width=4, height=1000, channel=1)  IN ['resnet_v1_50/SpatialSqueeze'] OUT ['resnet_v1_50/predictions/Softmax']
 81 softmax    resnet_v1_50/predictions/Softmax Ops 0.000000 Shape TensorShapes(batch=1, width=4, height=1000, channel=1)  IN ['resnet_v1_50/predictions/Reshape'] OUT ['resnet_v1_50/predictions/Reshape_1']
 82 reshape    resnet_v1_50/predictions/Reshape_1 Ops 0.000000 Shape TensorShapes(batch=1, width=4, height=1000, channel=1)  IN ['resnet_v1_50/predictions/Softmax'] OUT []
Outputs dict_keys(['resnet_v1_50/predictions/Reshape_1'])
 delete arch  resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block3/unit_3/bottleneck_v1/add True
 delete arch  resnet_v1_50/block3/unit_2/bottleneck_v1/add-resnet_v1_50/block3/unit_3/bottleneck_v1/add True
 delete arch  resnet_v1_50/block3/unit_3/bottleneck_v1/add-resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D True
 delete arch  resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D True
 delete arch  resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D True
 delete arch  resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block3/unit_4/bottleneck_v1/add True
 delete arch  resnet_v1_50/block3/unit_3/bottleneck_v1/add-resnet_v1_50/block3/unit_4/bottleneck_v1/add True
 delete arch  resnet_v1_50/block3/unit_4/bottleneck_v1/add-resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D True
 delete arch  resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D True
 delete arch  resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D True
 delete arch  resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block3/unit_5/bottleneck_v1/add True
 delete arch  resnet_v1_50/block3/unit_4/bottleneck_v1/add-resnet_v1_50/block3/unit_5/bottleneck_v1/add True
 delete arch  resnet_v1_50/block3/unit_5/bottleneck_v1/add-resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D True
 delete arch  resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D True
 delete arch  resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D True
 delete arch  resnet_v1_50/block3/unit_6/bottleneck_v1/shortcut/MaxPool-resnet_v1_50/block3/unit_6/bottleneck_v1/add True
 delete arch  resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block3/unit_6/bottleneck_v1/add True
 delete arch  resnet_v1_50/block3/unit_6/bottleneck_v1/add-resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D True
 delete arch  resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D True
 delete arch  resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D True
 delete arch  resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D-resnet_v1_50/block4/unit_1/bottleneck_v1/add True
 delete arch  resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block4/unit_1/bottleneck_v1/add True
 delete arch  resnet_v1_50/block4/unit_1/bottleneck_v1/add-resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D True
 delete arch  resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D True
 delete arch  resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D True
 delete arch  resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block4/unit_2/bottleneck_v1/add True
 delete arch  resnet_v1_50/block4/unit_1/bottleneck_v1/add-resnet_v1_50/block4/unit_2/bottleneck_v1/add True
 delete arch  resnet_v1_50/block4/unit_2/bottleneck_v1/add-resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D True
 delete arch  resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D True
 delete arch  resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D True
 delete arch  resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block4/unit_3/bottleneck_v1/add True
 delete arch  resnet_v1_50/block4/unit_2/bottleneck_v1/add-resnet_v1_50/block4/unit_3/bottleneck_v1/add True
 delete arch  resnet_v1_50/block4/unit_3/bottleneck_v1/add-resnet_v1_50/pool5 True
 delete arch  resnet_v1_50/pool5-resnet_v1_50/pool5/mul True
 delete arch  resnet_v1_50/pool5/mul-resnet_v1_50/logits/Conv2D True
 delete arch  resnet_v1_50/logits/Conv2D-resnet_v1_50/SpatialSqueeze True
 delete arch  resnet_v1_50/SpatialSqueeze-resnet_v1_50/predictions/Reshape True
 delete arch  resnet_v1_50/predictions/Reshape-resnet_v1_50/predictions/Softmax True
 delete arch  resnet_v1_50/predictions/Softmax-resnet_v1_50/predictions/Reshape_1 True
 delete node  resnet_v1_50/predictions/Reshape_1
 delete node  resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/Conv2D
 delete node  resnet_v1_50/block3/unit_6/bottleneck_v1/shortcut/MaxPool
True resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D
 delete node  resnet_v1_50/predictions/Shape_const_const
False resnet_v1_50/predictions/Shape_const_const
True resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D
True resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/block1/unit_1/bottleneck_v1/add
True resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D
True resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D
True resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool
True resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/block1/unit_2/bottleneck_v1/add
True resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/block2/unit_2/bottleneck_v1/add
True resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block1/unit_3/bottleneck_v1/add
True resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/pool1/MaxPool
True resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block2/unit_3/bottleneck_v1/add
True resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D
True input
True resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block2/unit_1/bottleneck_v1/add
True resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D
True resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D
True resnet_v1_50/block2/unit_4/bottleneck_v1/add
True resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/conv1/Conv2D
True resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D
True resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool
True resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D
True resnet_v1_50/block3/unit_2/bottleneck_v1/add
True resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D
True resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D
 delete node  resnet_v1_50/predictions/Reshape/shape_const
False resnet_v1_50/predictions/Reshape/shape_const
True resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D
True resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D
True resnet_v1_50/block3/unit_1/bottleneck_v1/add

True resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D
True resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D
Outputs dict_keys(['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D'])
  0 data       input Ops 0.000000 Shape TensorShapes(batch=4, width=224, height=224, channel=3)  IN [] OUT ['resnet_v1_50/conv1/Conv2D']
  1 conv2d     resnet_v1_50/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=112, height=112, channel=64)  IN ['input'] OUT ['resnet_v1_50/pool1/MaxPool']
  2 maxpool2d  resnet_v1_50/pool1/MaxPool Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/conv1/Conv2D'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D']
  3 conv2d     resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/pool1/MaxPool'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/add']
  4 conv2d     resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/pool1/MaxPool'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D']
  5 conv2d     resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D']
  6 conv2d     resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block1/unit_1/bottleneck_v1/add']
  7 add        resnet_v1_50/block1/unit_1/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D', 'resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block1/unit_2/bottleneck_v1/add']
  8 conv2d     resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/block1/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D']
  9 conv2d     resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D']
 10 conv2d     resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block1/unit_2/bottleneck_v1/add']
 11 add        resnet_v1_50/block1/unit_2/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=256)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block1/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool']
 12 maxpool2d  resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=256)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/add']
 13 conv2d     resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=56, height=56, channel=64)  IN ['resnet_v1_50/block1/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D']
 14 conv2d     resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=64)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D']
 15 conv2d     resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=256)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block1/unit_3/bottleneck_v1/add']
 16 add        resnet_v1_50/block1/unit_3/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=256)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool', 'resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D']
 17 conv2d     resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/add']
 18 conv2d     resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block1/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D']
 19 conv2d     resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D']
 20 conv2d     resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block2/unit_1/bottleneck_v1/add']
 21 add        resnet_v1_50/block2/unit_1/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D', 'resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block2/unit_2/bottleneck_v1/add']
 22 conv2d     resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D']
 23 conv2d     resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D']
 24 conv2d     resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block2/unit_2/bottleneck_v1/add']
 25 add        resnet_v1_50/block2/unit_2/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block2/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block2/unit_3/bottleneck_v1/add']
 26 conv2d     resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D']
 27 conv2d     resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D']
 28 conv2d     resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block2/unit_3/bottleneck_v1/add']
 29 add        resnet_v1_50/block2/unit_3/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=512)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block2/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool']
 30 maxpool2d  resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=512)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/add']
 31 conv2d     resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=28, height=28, channel=128)  IN ['resnet_v1_50/block2/unit_3/bottleneck_v1/add'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D']
 32 conv2d     resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=128)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D']
 33 conv2d     resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=512)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block2/unit_4/bottleneck_v1/add']
 34 add        resnet_v1_50/block2/unit_4/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=512)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool', 'resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D']
 35 conv2d     resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/add']
 36 conv2d     resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block2/unit_4/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D']
 37 conv2d     resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D']
 38 conv2d     resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block3/unit_1/bottleneck_v1/add']
 39 add        resnet_v1_50/block3/unit_1/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D', 'resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D'] OUT ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D', 'resnet_v1_50/block3/unit_2/bottleneck_v1/add']
 40 conv2d     resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D']
 41 conv2d     resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D'] OUT ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D']
 42 conv2d     resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D'] OUT ['resnet_v1_50/block3/unit_2/bottleneck_v1/add']
 43 add        resnet_v1_50/block3/unit_2/bottleneck_v1/add Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=1024)  IN ['resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D', 'resnet_v1_50/block3/unit_1/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D']
 44 conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_2/bottleneck_v1/add'] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D']
 45 conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'] OUT []
Floyd & Warshall
BFS
Name resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D Type conv2d Composed [] Inputs ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'] 

	 Name resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D Type conv2d Composed [] Inputs ['resnet_v1_50/block3/unit_2/bottleneck_v1/add'] 

 delete arch  resnet_v1_50/block3/unit_2/bottleneck_v1/add-resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block3/unit_2/bottleneck_v1/add
 delete arch  resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/Conv2D
 delete arch  resnet_v1_50/block3/unit_1/bottleneck_v1/add-resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block3/unit_1/bottleneck_v1/add-resnet_v1_50/block3/unit_2/bottleneck_v1/add
 delete arch  resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D-resnet_v1_50/block3/unit_1/bottleneck_v1/add
 delete arch  resnet_v1_50/block2/unit_4/bottleneck_v1/add-resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block2/unit_4/bottleneck_v1/add-resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/Conv2D
 delete arch  resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool-resnet_v1_50/block2/unit_4/bottleneck_v1/add
 delete arch  resnet_v1_50/block2/unit_3/bottleneck_v1/add-resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block2/unit_3/bottleneck_v1/add-resnet_v1_50/block2/unit_4/bottleneck_v1/shortcut/MaxPool
 delete arch  resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block2/unit_3/bottleneck_v1/add
 delete arch  resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/Conv2D
 delete arch  resnet_v1_50/block2/unit_2/bottleneck_v1/add-resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block2/unit_2/bottleneck_v1/add-resnet_v1_50/block2/unit_3/bottleneck_v1/add
 delete arch  resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block2/unit_2/bottleneck_v1/add
 delete arch  resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/Conv2D
 delete arch  resnet_v1_50/block2/unit_1/bottleneck_v1/add-resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block2/unit_1/bottleneck_v1/add-resnet_v1_50/block2/unit_2/bottleneck_v1/add
 delete arch  resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D-resnet_v1_50/block2/unit_1/bottleneck_v1/add
 delete arch  resnet_v1_50/block1/unit_3/bottleneck_v1/add-resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block1/unit_3/bottleneck_v1/add-resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/Conv2D
 delete arch  resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool-resnet_v1_50/block1/unit_3/bottleneck_v1/add
 delete arch  resnet_v1_50/block1/unit_2/bottleneck_v1/add-resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block1/unit_2/bottleneck_v1/add-resnet_v1_50/block1/unit_3/bottleneck_v1/shortcut/MaxPool
 delete arch  resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D-resnet_v1_50/block1/unit_2/bottleneck_v1/add
 delete arch  resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/Conv2D
 delete arch  resnet_v1_50/block1/unit_1/bottleneck_v1/add-resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/block1/unit_1/bottleneck_v1/add-resnet_v1_50/block1/unit_2/bottleneck_v1/add
 delete arch  resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D-resnet_v1_50/block1/unit_1/bottleneck_v1/add
 delete arch  resnet_v1_50/pool1/MaxPool-resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D
 delete arch  resnet_v1_50/pool1/MaxPool-resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/Conv2D
 delete arch  resnet_v1_50/conv1/Conv2D-resnet_v1_50/pool1/MaxPool
 delete arch  input-resnet_v1_50/conv1/Conv2D
 delete node  Name input Type data Composed [] Inputs [] 

 delete arch  resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/Conv2D
 delete node  Name resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/Conv2D Type conv2d Composed [] Inputs [] 

 delete arch  resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/Conv2D
 delete node  Name resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/Conv2D Type conv2d Composed [] Inputs [] 

 delete arch  resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/Conv2D
 delete node  Name resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/Conv2D Type conv2d Composed [] Inputs [] 

 delete arch  resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/Conv2D
 delete node  Name resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/Conv2D Type conv2d Composed [] Inputs [] 

 delete arch  resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D-resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/Conv2D
 delete arch  resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D-resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/Conv2D
 delete node  Name resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/Conv2D Type conv2d Composed [] Inputs [] 

Inputs dict_keys(['input'])
Outputs dict_keys(['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D'])
Inputs dict_keys(['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'])
Floyd & Warshall
BFS
  0 data       resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN [] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D']
  1 conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'] OUT []
 ############################################# 
 ######  CPU nodes Must Go
 ############################################# 
Inputs ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D']
Outputs ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D']
FPGA True: conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D  
FPGA True: data       resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D  
delete these dict_keys(['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'])
{'resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D': Name resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D Type conv2d Composed [] Inputs ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'] 
}
Schedule boost
0 data resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D False 1
1 conv2d resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D True 1
  0 data       resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN [] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D']
  1 conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D Ops 462422016.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'] OUT []
Outputs ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D']
Inputs  ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D']
Floyd & Warshall
BFS
 ############################################# 
 ######  Avg Pool -> Conv
 ############################################# 
 ############################################# 
 ######  Inner Products -> Conv
 ############################################# 
 ############################################# 
 ######  Scale -> Conv
 ############################################# 
Floyd & Warshall
BFS
 ############################################# 
 ######  topological schedule BFS
 ############################################# 
 ############################################# 
 ######  WEIGHT & BIAS into Tensors
 ############################################# 
 ############################################# 
 ######  Conv + Pool -> single
 ############################################# 
 ############################################# 
 ######  Conv + Elt -> Elt
 ############################################# 
 ############################################# 
 ######  topological DFS
 ############################################# 
DFS_t resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D
 ############################################# 
 ######  TFS
 ############################################# 
 ############################################# 
 ######  INC
 ############################################# 
INC
 ############################################# 
 ######  Singleton
 ############################################# 
  0 data       resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D Ops 0.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN [] OUT ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D']
  1 conv2d     resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D Ops 462422016.000000 Shape TensorShapes(batch=4, width=14, height=14, channel=256)  IN ['resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D'] OUT []
 ############################################# 
 ######  Given a Graph and Schedule boost : We crete Live Tensor
 ############################################# 
 ############################################# 
 ######  Reset Live Structure
 ############################################# 
 ############################################# 
 ######  Attempting Code Generation boost
 ############################################# 
 ############################################# 
 ######  Element Wise: reuse one of the operands
 ############################################# 
 ############################################# 
 ######  Concatenation: I love concatenation memory reuse
 ############################################# 
 ############################################# 
 ######  Memory Management given a Schedule
 ############################################# 
Namespace(address=None, avgpool_as_convolution=True, backwardcut='resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D', biaspatch='true', caffemodel=None, circus=False, fc=False, final=False, firstlayerreshape=False, forwardcut='resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D', framework='tensorflow', inner_as_convolution=True, inshapes='[4,224,224,3]', json='SC/work/manasa/tf/all/45/meta1.json', network='examples/tf_resnetv1_50_imagenet_224_224_6.97G/quantized/quantize_eval_model.pb', nocpu=True, operation_fusion='true', operation_fusion_elt='true', operation_fusion_pool_conv=False, output='SC/work/manasa/tf/all/45/instr.asm', parallelismgraphalgorithm=None, parallelismstrategy="['bottom','top']", params='SC/work/manasa/tf/all/45/params.txt', prefetch=False, quant='examples/tf_resnetv1_50_imagenet_224_224_6.97G/quantized/temp_fix.txt', skip=False, softwarepipeline='true')
Name resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_weight Parameter True	Space 4718592 bits, BitePerPixel 8 Fraction 8 Start 0 End 4718592	Specifier 0 Layout 3 Time 1 Strategies None None	Shape  [] CNN_Shape TensorShapes(batch=256, width=3, height=3, channel=256)
int8
	reshape_wgt_to_ddr() (256, 3, 3, 256) done ... 
0x30000000 0x30090000 Name resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_weight Parameter True	Space 4718592 bits, BitePerPixel 8 Fraction 8 Start 0 End 4718592	Specifier 0 Layout 3 Time 1 Strategies None None	Shape  [] CNN_Shape TensorShapes(batch=256, width=3, height=3, channel=256)
589824
	dump_ddr_data() done ...
int32
	reshape_bias_to_ddr() done ...
0x30090000 0x30090400 Name resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_bias Parameter True	Space 8192 bits, BitePerPixel 32 Fraction 5 Start 4718592 End 4726784	Specifier 0 Layout 3 Time 2 Strategies None None	Shape  [] CNN_Shape TensorShapes(batch=1, width=1, height=1, channel=256)
1024
	dump_ddr_data() done ...
XXXXX resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D
Step  resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D
Step  resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D is an input
WARNING resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D data WARNING
Step  resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D
resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D {'id': 1, 'depth': 1, 'visited': False, 'color': 1, 'singleton': 0, 'span': 0, 'dfs': 2, 'tfs': 1, 'inc': 0, 'sn': 1.4, 'compute': 0, 'prefetch': False, 'parallel': False, 'parallel_tail': False, 'parallel_head': False}
Memory access IN ddr PAR pa  TMP fm  OUT ddr resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D memory type layer  parallelism 3 [1, 0, 0, 0, 1, 1]  
0 True 2048 resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_weight
0 True 2048 resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D_bias
1 SWAP SIZE resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D 4734976 7946240
 ############################################# 
 ######  Naive instruction dependency
 ############################################# 
 ############################################# 
 ######  Code Generation at Node Level and then Recursively
 ############################################# 
Dependency ON 0 0 CUR 0 BY 0 
1 4 resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D ON 0 CUR 0 BY 1
2 4 resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D ON 0 CUR 4 BY 2
3 4 bracket ON 2 CUR 2 BY 0
 ############################################# 
 ######  Code Generation at Node Level and then Recursively
 ############################################# 
CODE resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D conv2d
10 8 [825753.6, 458752] [458752, 229376]
BATCH IN  Shape [4, 14, 14, 256] Heights [10, 5] 
BATCH OUT Shape [4, 14, 14, 256] Heights [8, 6] 
input 0 4734976
 ############################################# 
 ######  Success boost
 ############################################# 
 ############################################# 
 ######  Writing code to file:SC/work/manasa/tf/all/45/instr.asm
 ############################################# 
Namespace(address=None, avgpool_as_convolution=True, backwardcut='resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D', biaspatch='true', caffemodel=None, circus=False, fc=False, final=False, firstlayerreshape=False, forwardcut='resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/Conv2D', framework='tensorflow', inner_as_convolution=True, inshapes='[4,224,224,3]', json='SC/work/manasa/tf/all/45/meta1.json', network='examples/tf_resnetv1_50_imagenet_224_224_6.97G/quantized/quantize_eval_model.pb', nocpu=True, operation_fusion='true', operation_fusion_elt='true', operation_fusion_pool_conv=False, output='SC/work/manasa/tf/all/45/instr.asm', parallelismgraphalgorithm=None, parallelismstrategy="['bottom','top']", params='SC/work/manasa/tf/all/45/params.txt', prefetch=False, quant='examples/tf_resnetv1_50_imagenet_224_224_6.97G/quantized/temp_fix.txt', skip=False, softwarepipeline='true')
{'inputs': {'input': {'name': 'input/aquant', 'shape': [4, 224, 224, 3], 'address': 425984, 'inKernelW': 7, 'inStrdW': 2, 'padLft': 3, 'padRt': 3, 'channelAugmentationMode': False, 'druMode': True, 'druSrcBufSize': 16777216, 'druDstBufSize': 16777216, 'inDDRSize': 150528}}, 'outputs': {'resnet_v1_50/conv1/Conv2D': {'name': 'resnet_v1_50/conv1/Relu/aquant', 'shape': [4, 112, 112, 64], 'address': 26116096, 'outDDRSize': 802816}}, 'swapBufSize': 16777216, 'kernel': 'dpdpuv3_wrapper', 'xclbin': 'tests/app/models/dpuv3int8_resnet50', 'debugDInFile': 'input.bin', 'debugGoldenFile': 'resnet_v1_50_block4_unit_3_bottleneck_v1_Relu_aquant.fix.bin', 'debugMode': True, 'usexmodel': False, 'xmodelFile': 'resnet50_case73_compiled_0922.xmodel'}
{1: {'data': Name resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D_weight Parameter True	Space 2097152 bits, BitePerPixel 8 Fraction 9 Start 0 End 262144	Specifier  Layout -1 Time 0 Strategies None None	Shape  [] CNN_Shape TensorShapes(batch=256, width=1, height=1, channel=1024), 'data_type': 'float32', 'shape': [256, 1, 1, 1024], 'kernel_width': 1, 'kernel_height': 1, 'kernel_1': TensorShapes(batch=0, width=1, height=1, channel=0), 'stride_width': 1, 'stride_height': 1, 'strides_1': TensorShapes(batch=0, width=1, height=1, channel=0), 'bit_width': 8, 'fix_point': 9, 'if_signed': True, 'round_mode': 'STD_ROUND'}, 2: {'data': Name resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/Conv2D_bias Parameter True	Space 8192 bits, BitePerPixel 32 Fraction 5 Start 0 End 256	Specifier  Layout -1 Time 0 Strategies None None	Shape  [] CNN_Shape TensorShapes(batch=1, width=1, height=1, channel=256), 'data_type': 'float32', 'shape': [256], 'kernel_width': 1, 'kernel_height': 1, 'kernel_1': TensorShapes(batch=0, width=1, height=1, channel=0), 'stride_width': 1, 'stride_height': 1, 'strides_1': TensorShapes(batch=0, width=1, height=1, channel=0), 'bit_width': 8, 'fix_point': 5, 'if_signed': True, 'round_mode': 'STD_ROUND'}, -1: {'bit_width': 8, 'fix': True, 'fix_point': 4, 'if_signed': True, 'quant_in_bit_width': 8, 'quant_in_quantize_pos': 4, 'quant_in_round_mode': 1, 'quant_in_signed': 1, 'quant_out_bit_width': 8, 'quant_out_quantize_pos': 4, 'quant_out_round_mode': 1, 'quant_out_signed': 1, 'round_mode': 'DPU_ROUND', 'kernel_width': 1, 'kernel_height': 1, 'kernel_1': TensorShapes(batch=0, width=1, height=1, channel=0), 'stride_width': 1, 'stride_height': 1, 'strides_1': TensorShapes(batch=0, width=1, height=1, channel=0), 'relu': True}, 'relu': 'relu'}
SC/work/manasa/tf/all/45/ meta1 json
